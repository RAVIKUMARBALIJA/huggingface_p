{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer,TFAutoModelForSequenceClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "checkpoint='distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer=AutoTokenizer.from_pretrained(checkpoint)\n",
    "model=TFAutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents=\"I hate you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tokenizer.tokenize(sents)\n",
    "ids=tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1045, 5223, 2017]"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=tf.constant([ids])\n",
    "output_logits=model(input_ids).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.98728615,  1.1817394 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "output_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1], dtype=int64)>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "tf.argmax(tf.math.softmax(output_logits),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents=[\"I've been waiting for a HuggingFace course my whole life.\",\"I hate this so much\",'I Like you soo much']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[tokenizer.tokenize(sent) for sent in sents]\n",
    "ids=[tokenizer.convert_tokens_to_ids(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length=0\n",
    "for input_id in ids:\n",
    "    if len(input_id)>max_input_length:\n",
    "        max_input_length=len(input_id)\n",
    "for idx,input_id in enumerate(ids):\n",
    "    if len(input_id)<max_input_length:\n",
    "        pad_length=max_input_length-len(input_id)\n",
    "        ids[idx]+=list(np.full((1,pad_length),tokenizer.pad_token_id,dtype=int).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1045,\n",
       "  1005,\n",
       "  2310,\n",
       "  2042,\n",
       "  3403,\n",
       "  2005,\n",
       "  1037,\n",
       "  17662,\n",
       "  12172,\n",
       "  2607,\n",
       "  2026,\n",
       "  2878,\n",
       "  2166,\n",
       "  1012],\n",
       " [1045, 5223, 2023, 2061, 2172, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1045, 2066, 2017, 17111, 2172, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=tf.constant(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 14), dtype=int32, numpy=\n",
       "array([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "         2607,  2026,  2878,  2166,  1012],\n",
       "       [ 1045,  5223,  2023,  2061,  2172,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 1045,  2066,  2017, 17111,  2172,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]])>"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[-2.72762    2.8789363]\n [ 2.7984848 -2.4121716]\n [-0.4905542  0.6014412]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output_logits=model(input_ids).logits\n",
    "print(output_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 0, 1], dtype=int64)>"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "tf.argmax(tf.math.softmax(output_logits),axis=1)"
   ]
  },
  {
   "source": [
    "### With Attention mask"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878\n   2166  1012]\n [ 1045  5223  2023  2061  2172     0     0     0     0     0     0     0\n      0     0]\n [ 1045  2066  2017 17111  2172     0     0     0     0     0     0     0\n      0     0]]\n"
     ]
    }
   ],
   "source": [
    "ids_np=input_ids.numpy()\n",
    "print(ids_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 14), dtype=int32, numpy=\n",
       "array([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "         2607,  2026,  2878,  2166,  1012],\n",
       "       [ 1045,  5223,  2023,  2061,  2172,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 1045,  2066,  2017, 17111,  2172,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]])>"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask(tensor):\n",
    "    attention_mask=[]\n",
    "    for arr in tensor:\n",
    "        ai=[]\n",
    "        for i in arr:\n",
    "            if i!=0:\n",
    "                ai.append(1)\n",
    "            else:\n",
    "                ai.append(0)\n",
    "        attention_mask.append(ai)\n",
    "    return attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask=create_attention_mask(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logits=model(input_ids,attention_mask=create_attention_mask(input_ids)).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-2.72762  ,  2.8789363],\n",
       "       [ 3.174391 , -2.6848435],\n",
       "       [-2.141855 ,  2.3865533]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "output_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 0, 1], dtype=int64)>"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "tf.argmax(tf.math.softmax(output_logits),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}